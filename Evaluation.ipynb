{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testando se o ambiente está funcionando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('teste')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importando bibliotecas para explorar os diretórios do computador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verificando todos os arquivos obtidos da fonta de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"E://dump\"\n",
    "\n",
    "dump_files = listdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tendo certeza que é possível ler os dados do GHtorrent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.read_csv(join(path, 'project_languages.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Acredito que será possível partir dos pullrequest para observar quais repositórios possuem contribuições ou não. Além disso, após pesquisar (https://levelup.gitconnected.com/how-to-mine-github-data-in-2022-e9c70b3f61d3) parece que os dados de 2015 possuem uma estrutura diferente. Então irei tentar filtrar eles fora do meu dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_pullrequests = pd.read_csv(join(path, 'pull_requests.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_pullrequests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um artigo que mostra a estrutura dos arquivos do GHtorrent https://gousios.org/pub/ghtorrent-dataset-toolsuite.pdf\n",
    "misturando com esse aqui também https://github.com/ghtorrent/ghtorrent.org/blob/master/files/schema.pdf\n",
    "Então irei adicionar o nome nas colunas, acabei retirando a coluna pullrequest_id pois ela não fazia sentido no contexto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_pullrequests.columns = [\"id\", \"head_repo_id\", \"base_repo_id\", \"head_commit_id\", \"base_commit_id\", \"intra_branch_id\",\"merged\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como os pull requests não possuem data de criação tentarei filtrar através dos commits que eles estão ligados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Função para calcular o número total de chunks\n",
    "# def get_total_chunks(filename, chunksize):\n",
    "#     # Contar o número total de linhas no arquivo\n",
    "#     total_lines = sum(1 for _ in open(filename)) - 1  # Subtrai 1 por causa do cabeçalho\n",
    "#     # Calcular o número total de chunks\n",
    "#     total_chunks = (total_lines // chunksize) + (1 if total_lines % chunksize != 0 else 0)\n",
    "#     return total_chunks\n",
    "\n",
    "# # Exemplo de uso\n",
    "# filename = join(path, 'commits.csv')\n",
    "# chunksize = 5000000\n",
    "# total_chunks = get_total_chunks(filename, chunksize)\n",
    "# print(f\"Total de chunks: {total_chunks}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_commits_19 = pd.DataFrame({},columns=[\"id\", \"sha\", \"author_id\", \"commiter_id\", \"project_id\", \"created_at\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def checkDate(df):\n",
    "#   return pd.to_datetime(df.iloc[0]['created_at']) > pd.to_datetime('2019-01-01') or pd.to_datetime(df.iloc[-1]['created_at']) > pd.to_datetime('2019-01-01')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for chunk in df_commits:\n",
    "#     chunk.map(lambda row: chechRowDate(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i=0\n",
    "\n",
    "# for chunk in df_commits:\n",
    "#     if checkDate(chunk):\n",
    "#         chunk.to_csv(f'E:/dump/commits_greater_than_2k19_{i}')\n",
    "\n",
    "#     i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtrando os repositórios Open Source"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Devido a grande quantidade de commits, não foi possível os utilizar como filtro de projetos open-source. Nesse caso, iremos utilizar a relação project_members para encontrar quais projetos são relevantes, ou seja, que possuem contribuintes além do dono."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_project_members = pd.read_csv(join(path, 'project_members.csv'), names=[\"repo_id\", \"user_id\", \"created_at\", \"ext_ref_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_project_members"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_count_members = df_project_members.groupby(\"repo_id\", as_index=False)[\"user_id\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_count_members"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_open_source_members = df_count_members[df_count_members[\"user_id\"]>10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_open_source_members"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Devivo a datação dos dados iremos filtrar somente os membros a partir de 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_project_members = df_project_members.loc[\n",
    "    (pd.to_datetime(df_project_members['created_at']) > pd.to_datetime(\"01-01-2019\")) & \n",
    "    (df_project_members['repo_id'].isin(df_open_source_members['repo_id']))\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transforma o campo de data em data\n",
    "\n",
    "df_project_members['created_at'] = pd.to_datetime(df_project_members['created_at'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_project_members"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataframe alvo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir do estudo Recommending GitHub Projects for Developer Onboarding podemos extrair alguns atributos a serem extraídos do dataset para que seja estudado o quão receptivo um repositório é, são eles:\n",
    "\n",
    "- Crescimento do Projeto: Quantidade de commits do projeto no momento de iniciação\n",
    "- Data de criação do projeto: Projetos mais novos tendem a atrair mais desenvolvedores\n",
    "- Momento de primeira contribuição: quando o projeto começa a receber contribuidores\n",
    "- Momento da última contribuição: se a equipe do projeto se manter estável significa que existe menos oportunidades de onboarding\n",
    "- Momento do primeiro commit: primeiro commit do projeto, a partir de quando passa a aceitar contribuições\n",
    "- Momento do último commit: se o projeto receber muitos commits, mas nao tiver tanto onboarding significa q esse projeto necessita de mais contribuintes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#objetivo final\n",
    "\n",
    "df_onboardings = pd.DataFrame({}, columns=[\"repo_id\", \"created_at\", \"total_commits\",\"first_onboarding\", \"last_onboarding\", \"first_commit\", \"last_commit\", \"user_id\", \"onboarding_date\"])\n",
    "\n",
    "df_onboardings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks_commits = pd.read_csv(join(path, 'commits.csv'), names=[\"id\", \"sha\", \"author_id\", \"commiter_id\", \"project_id\", \"created_at\"], chunksize=5000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora irei filtrar somente os commits dos projetos selecionados como open source após o ano de 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pegando os commits referentes aos repositórios classificados como Open Source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#i=0\n",
    "#for chunk in chunks_commits:\n",
    "#        df_commit = chunk[chunk['project_id'].isin(df_project_members['repo_id'])]\n",
    "#        df_commit.to_csv(f'E:/dump/open_source/open_source_commits_{i}.csv')\n",
    "#        i += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_open_source_files = listdir(join(path, 'open_source'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descobrindo usuários iniciantes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para determinar quais contribuições são referentes a iniciantes teremos que descobrir qual foi o primeiro commit de cada usuário e qual foi o repositório dele"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_user_commit_by_chunks = []\n",
    "\n",
    "i=0\n",
    "for file in dump_open_source_files:\n",
    "    print(\"lendo arquivo: \", i)\n",
    "    df_commit = pd.read_csv(join(path,'open_source',file))\n",
    "    df_commit[\"created_at\"] = pd.to_datetime(df_commit[\"created_at\"])\n",
    "    first_user_commit_by_chunks.append( df_commit.groupby([\"author_id\"], as_index=False).agg({\"created_at\": np.min}))\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_first_user_commit = pd.concat(first_user_commit_by_chunks)\n",
    "\n",
    "#df_first_user_commit = df_first_user_commit.groupby(\"author_id\", as_index=False).agg({\"created_at\": np.min})\n",
    "\n",
    "df_first_user_commit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "testando um método de filtrar os primeiros commits em repositórios open source de cada usuário sem q o ID e o repo_id sejam abstraídos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_min_date_row(group):\n",
    "    min_row = group.loc[group['created_at'].idxmin()]\n",
    "    return min_row\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_user_commit_by_chunks2 = []\n",
    "\n",
    "i=0\n",
    "for file in dump_open_source_files:\n",
    "    print(\"lendo arquivo: \", i)\n",
    "    df_commit = pd.read_csv(join(path,'open_source',file))\n",
    "    df_commit[\"created_at\"] = pd.to_datetime(df_commit[\"created_at\"])\n",
    "    first_user_commit_by_chunks2.append(df_commit.groupby('author_id').apply(get_min_date_row).reset_index(drop=True))\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_user_commit_by_chunks2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_first_user_commit2 = pd.concat(first_user_commit_by_chunks2)\n",
    "\n",
    "df_first_user_contrib = df_first_user_commit2.groupby('author_id').apply(get_min_date_row).reset_index(drop=True)\n",
    "\n",
    "df_first_user_contrib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_first_user_contrib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "filtrando somente as contribuições posteriores a 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_first_user_commit = df_first_user_commit.loc[df_first_user_commit['created_at'] > pd.to_datetime('2019-01-01')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora calculamos quantos commits cada projeto possui no momento de onboard do dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_total_commits(row):\n",
    "    repo_id = row['project_id']\n",
    "    date = row['created_at']\n",
    "    total_commits = 0\n",
    "    for file in dump_open_source_files:\n",
    "        chunk = pd.read_csv(dump_open_source_files)\n",
    "        total_commits += chunk.loc[(chunk['project_id'] == repo_id) & (pd.to_datetime(chunk['created_at']) <= pd.to_datetime(date))].shape[0]\n",
    "\n",
    "    return total_commits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "['total_commits'] = df_first_commit_user.apply(get_total_commits, axis=1)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pegar os detalhes do projeto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_projetos = pd.read_csv(join(path, \"projects.csv\"), names=[\"id\", \"url\", \"owner_id\", \"name\", \"descriptor\", \"language\", \"created_at\", \"forked_from\", \"deleted\", \"updated_at\"], na_values=\"not available\", on_bad_lines='warn', chunksize=5000000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
